---
title: "process meter readings"
author: "Lizzie Pearmain"
date: "April 2023"
output: 
  github_document:
    toc: true
    toc_depth: 2
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## setup

Here we load any required packages, source functions, and read in metadata.

```{r set-up-read-meta, message=FALSE, warning=FALSE}

## load packages
library(dplyr)
library(lubridate)
library(tidyr)
library(readxl)
library(ggplot2)

## source functions
source("functions.R")

## read metadata
meta <- read.csv("meter_metadata.csv")

```

## read meters

Here we read in the data from all the meters and save into one big file. 

First we'll test the functions on one file (this chunk was only used during development to test and debug, so it's now commented out and doesn't run).

```{r test-read}

## test the function for reading in a file and converting it to a daily sum
# t <- read_meter_xlsx("data_meters/02B0F5-S02 DB-3D Power.xlsx")
# str(t)   # check what the data look like
# head(t)

## test the function for calculating daily sums
# t_daily <- calc_daily_sums(t)
# head(t_daily)
# str(t_daily)

# rm(t, t_daily)  # clean up the test file

```

Now we get a list of the files we *should* have in the `data_meters` folder (i.e. all 39 meter names from the `meta` table followed by `.xlsx`).

We check that all the meter files are present in the `data_meters` folder, and print out a list of any that are missing.

We read in all the meter files using `lapply()` with the `read_meter_xlsx()` function tested above, and `rbind()` all the data from each meter into one big data frame. We also remove any duplicated rows in case of time period overlaps.

*Note: we need to work out how to allow processing of multiple sets of files at the same time, e.g. the set of downloads from 2022-06 and from 2022-12.* Where we have multiple `.xlsx` files from a single meter, this code may fail, and it may be better to just read in all `.xlsx` files in the `data_meters` folder, check the `meter_ref` field against the metadata to make sure all the files can be matched to a `meter_ref` in the metadata, and remove any duplicates in `meter_ref`&`date` i.e. overlapping timestamps.

```{r read-all-files}

## vector of all the filenames
files <- paste(meta$meter_ref, ".xlsx", sep="")

## check all the files are present in the data_meters folder,
##  otherwise print out a list of which files are missing
if (! length(files[which(! files %in% list.files("data_meters"))]) == 0) {
  stop(paste("Not all the meter files could be found in the data_meters folder.",
             "The following files are missing:\n",
             paste(files[which(! files %in% list.files("data_meters"))], collapse="\n ")
                   ))
}

## read in all the files and bind into one data frame
filepaths <- paste("data_meters/", files, sep="")  # make full filepaths instead of just filenames
df.list <- lapply(filepaths, read_meter_xlsx)      # apply the read_meter_xlsx to all filepaths and save all dataframes in a list
df <- do.call(rbind, df.list)                      # rbind together all the dataframes in the list
rm(df.list)                                        # clean up by deleting the list

## remove any duplicated rows
df$duplicated <- duplicated(df)             # new field indicating if row is a full duplicate of an earlier row
df_new <- subset(df, duplicated == FALSE)   # subset to only rows where duplicated = FALSE
if (nrow(df_new) != nrow(df)) {             # if any rows were removed, print out a note saying how many
  cat("NOTE:", (nrow(df) - nrow(df_new)), "duplicated row(s) removed.")
}
df <- df_new  # replace old data with new
rm(df_new)    # clean up
df$duplicated <- NULL  # remove the duplicated field - no longer needed

head(df)  # check data structure
str(df)   # check column formats

```

Here we can do some debugging if needed, to remove any usage values that are way too high (there are sometimes glitches causing dodgy readings).


## sum daily usage

Since we don't need all the half-hourly readings, we use the `calc_daily_sums()` function which performs a rowwise sum to make an overall usage value per meter per day. It also removes all the half-hourly reading columns.

```{r calc-daily-sums}

## turn this into daily sums instead of raw data
df <- calc_daily_sums(df)

head(df)
str(df)

```

## merge metadata

Here we merge in the metadata (extra columns on meter group, meter location, how the usage from that meter group should be apportioned between CCI orgs, etc), joining by the `meter_ref` field which is present in both the meter readings data `df` and the metadata `meta`.

```{r merge-in-meta}

df <- merge(df, meta)  # merge metadata in

head(df)  # check the new columns
str(df)

```

## fill power/lighting gaps

Here we sort out the fact that some meters are just power, some are just lighting, and some are both power and lighting.

The custom function `combine_power_lighting()` takes the daily sum data and uses `tidyr::pivot_wider()` to match the power/lighting/both values for each pair of meters (i.e. each unique `meter_group`). Look in the `functions.R` file to see the code for this function.

Since each pair of meters is combined into one, we end up with half the number of rows in the dataset, and a few extra columns indicating the usage for that `meter_group` from power (`pwr`), lighting (`ltg`) and both power & lighting (`both`).

```{r power-lighting}

## test on a subset of the dataset (commented out - used only for testing)
# t_df <- subset(df, meter_group %in% c("02B0F5-DB-3D", "02B0FB-DB-ET-1"))
# t_new <- combine_power_lighting(t_df)

## apply the function to the whole dataset
df_new <- combine_power_lighting(df)

## we should have half as many rows now - each pair of meters has been combined into one row
nrow(df_new) / nrow(df)

## check data - usage column has been replaced with pwr / ptg / both
head(df_new)
str(df_new)

## update df and clean up
df <- df_new
rm(df_new)

```

## write to file

Write the resulting dataframe to file. This file is not tracked by git (it's in the `.gitignore` file).

```{r write-to-file}

write.csv(df, "processed_meter_data.csv", row.names=FALSE)

```


*End.*


